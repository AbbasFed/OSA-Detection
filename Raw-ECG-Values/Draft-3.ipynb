{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "566d29cd-c051-445b-a965-9bdd81b2e32f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\abbas\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import os\n",
    "import scipy.signal as sgn\n",
    "from tqdm import tqdm\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from scipy.signal import cheby1, filtfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837e9718-0d1f-4aea-bec8-49663ea1933e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# File paths\n",
    "train_files = [f\"a{str(i).zfill(2)}\" for i in range(1, 21)] + [f\"b{str(i).zfill(2)}\" for i in range(1, 6)] + [f\"c{str(i).zfill(2)}\" for i in range(1, 11)]\n",
    "test_files = [f\"x{str(i).zfill(2)}\" for i in range(1, 36)]\n",
    "base_path = \"apnea-ecg/1.0.0/\"\n",
    "train_paths = [os.path.join(base_path, file) for file in train_files]\n",
    "test_paths = [os.path.join(base_path, file) for file in test_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dede400d-6537-4615-a578-474ebcefc295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Chebyshev Filter\n",
    "def apply_chebyshev_filter(signal, lowcut=0.5, highcut=40, fs=100, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = cheby1(order, 0.5, [low, high], btype='band')\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "# Function to load and preprocess the ECG signal\n",
    "def load_ecg_and_segment(file, segment_duration=10, fs=100):\n",
    "    if not os.path.exists(f\"{file}.hea\") or not os.path.exists(f\"{file}.dat\"):\n",
    "        print(f\"File not found: {file}.hea or {file}.dat\")\n",
    "        return [], []\n",
    "    \n",
    "    record = wfdb.rdrecord(file)\n",
    "    annotation = wfdb.rdann(file, 'apn')\n",
    "\n",
    "    signal = record.p_signal[:, 0]\n",
    "    filtered_signal = apply_chebyshev_filter(signal)\n",
    "\n",
    "    segments = []\n",
    "    labels = []\n",
    "    samples_per_segment = segment_duration * fs\n",
    "\n",
    "    for i, samp in enumerate(annotation.sample):\n",
    "        start = max(samp - samples_per_segment // 2, 0)\n",
    "        end = start + samples_per_segment\n",
    "        if end > len(filtered_signal):\n",
    "            break\n",
    "        segment = filtered_signal[start:end]\n",
    "        segments.append(segment)\n",
    "        labels.append(1 if annotation.symbol[i] == 'A' else 0)\n",
    "        \n",
    "    return np.array(segments), np.array(labels)\n",
    "\n",
    "# Load and prepare the full dataset\n",
    "def prepare_data(paths):\n",
    "    data, labels = [], []\n",
    "    for path in tqdm(paths):\n",
    "        segments, seg_labels = load_ecg_and_segment(path)\n",
    "        if segments.size > 0:  \n",
    "            data.extend(segments)\n",
    "            labels.extend(seg_labels)\n",
    "    return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55da9faf-3c12-4234-842c-e747d976c979",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:04<00:00,  8.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:04<00:00,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training segments: 17045, Test segments: 17268\n",
      "Training data shape: (17045, 1000, 1)\n",
      "Training labels shape: (17045,)\n",
      "Test data shape: (17268, 1000, 1)\n",
      "Test labels shape: (17268,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load training and validation data, and shuffle\n",
    "X_train, y_train = prepare_data(train_paths)\n",
    "X_test, y_test = prepare_data(test_paths)\n",
    "\n",
    "# Shuffle the data\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "# Print the number of segments loaded for verification\n",
    "print(f\"Training segments: {len(X_train)}, Test segments: {len(X_test)}\")\n",
    "\n",
    "# Reshape data for model input format\n",
    "X_train = X_train[..., np.newaxis]  # Adding channel dimension\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a994c426-59e4-4a7b-bf20-dbb35dcece8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (14610, 1000, 1)\n",
      "Validation data shape: (2435, 1000, 1)\n",
      "Train labels shape: (14610,)\n",
      "Validation labels shape: (2435,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Splitting the training data into train and validation sets with StratifiedKFold\n",
    "strat_kfold = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "train_indices, val_indices = next(strat_kfold.split(X_train, y_train))\n",
    "\n",
    "# Creating training and validation sets\n",
    "X_ctrain, X_val = X_train[train_indices], X_train[val_indices]\n",
    "y_ctrain, y_val = y_train[train_indices], y_train[val_indices]\n",
    "\n",
    "# Print shapes of the resulting sets for verification\n",
    "print(\"Train data shape:\", X_ctrain.shape)\n",
    "print(\"Validation data shape:\", X_val.shape)\n",
    "print(\"Train labels shape:\", y_ctrain.shape)\n",
    "print(\"Validation labels shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c624576-e26e-4a11-a86b-ae445d0e4e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, regularizers, optimizers\n",
    "\n",
    "def build_cnn_lstm_model(input_shape):\n",
    "    # Input layer\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x_bn = layers.BatchNormalization()(input_layer)\n",
    "    \n",
    "    # First branch: Conv1D with kernel size 125 and MaxPooling with L2 regularization\n",
    "    branch1 = layers.Conv1D(24, kernel_size=125, strides=1, activation='relu', \n",
    "                            padding='same', kernel_regularizer=regularizers.l2(0.001))(x_bn)\n",
    "    branch1 = layers.MaxPooling1D(pool_size=2, strides=1, padding='same')(branch1)\n",
    "    \n",
    "    # Second branch: Conv1D with kernel size 15 and MaxPooling with L2 regularization\n",
    "    branch2 = layers.Conv1D(24, kernel_size=15, strides=1, activation='relu', \n",
    "                            padding='same', kernel_regularizer=regularizers.l2(0.001))(x_bn)\n",
    "    branch2 = layers.MaxPooling1D(pool_size=2, strides=1, padding='same')(branch2)\n",
    "    \n",
    "    # Third branch: Conv1D with kernel size 5 and MaxPooling with L2 regularization\n",
    "    branch3 = layers.Conv1D(24, kernel_size=5, strides=1, activation='relu', \n",
    "                            padding='same', kernel_regularizer=regularizers.l2(0.001))(x_bn)\n",
    "    branch3 = layers.MaxPooling1D(pool_size=2, strides=1, padding='same')(branch3)\n",
    "    \n",
    "    # Concatenate the outputs of the three branches\n",
    "    concatenated = layers.Concatenate(axis=-1)([branch1, branch2, branch3])\n",
    "    \n",
    "    # Additional MaxPooling after concatenation\n",
    "    x = layers.MaxPooling1D(pool_size=3, strides=1, padding='same')(concatenated)\n",
    "    \n",
    "    # Adjust the Conv1D layer to match dimensions for addition\n",
    "    conv_adjusted = layers.Conv1D(72, kernel_size=3, strides=1, activation='relu', \n",
    "                                  padding='same', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.Add()([x, conv_adjusted])\n",
    "    \n",
    "    # Fully Connected and Dropout layers with L2 regularization\n",
    "    x = layers.Dense(48, activation='leaky_relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.Dropout(0.5)(x)  # Dropout for regularization\n",
    "    \n",
    "    # Global Pooling layer\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # LSTM layer\n",
    "    # x = layers.Reshape((1, -1))(x)  # Reshape for LSTM input\n",
    "    # x = layers.LSTM(64, kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    \n",
    "    # Output layer\n",
    "    output_layer = layers.Dense(2, activation='softmax', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    \n",
    "    # Define the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da14a4f4-9571-4ec0-af55-5f6437a78fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 1000, 1)]            0         []                            \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 1000, 1)              4         ['input_2[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 1000, 24)             3024      ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 1000, 24)             384       ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)           (None, 1000, 24)             144       ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPoolin  (None, 1000, 24)             0         ['conv1d_4[0][0]']            \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPoolin  (None, 1000, 24)             0         ['conv1d_5[0][0]']            \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPoolin  (None, 1000, 24)             0         ['conv1d_6[0][0]']            \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 1000, 72)             0         ['max_pooling1d_4[0][0]',     \n",
      " )                                                                   'max_pooling1d_5[0][0]',     \n",
      "                                                                     'max_pooling1d_6[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPoolin  (None, 1000, 72)             0         ['concatenate_1[0][0]']       \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)           (None, 1000, 72)             15624     ['max_pooling1d_7[0][0]']     \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 1000, 72)             0         ['max_pooling1d_7[0][0]',     \n",
      "                                                                     'conv1d_7[0][0]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1000, 48)             3504      ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 1000, 48)             0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 48)                   0         ['dropout_1[0][0]']           \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 2)                    98        ['global_average_pooling1d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22782 (88.99 KB)\n",
      "Trainable params: 22780 (88.98 KB)\n",
      "Non-trainable params: 2 (8.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compile the model with specified learning rate\n",
    "input_shape = (1000, 1)  # Adjust as per 10-second segments at 100 Hz sampling rate\n",
    "model = build_cnn_lstm_model(input_shape)\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model summary for verification\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17fb9435-c9ec-4c0a-9cc2-4c7b4392a9b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Users\\abbas\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\abbas\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "914/914 [==============================] - ETA: 0s - loss: 0.6799 - accuracy: 0.6761\n",
      "Epoch 1: val_loss improved from inf to 0.68605, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "914/914 [==============================] - 44s 47ms/step - loss: 0.6799 - accuracy: 0.6761 - val_loss: 0.6861 - val_accuracy: 0.6559 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "  1/914 [..............................] - ETA: 41s - loss: 0.7517 - accuracy: 0.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913/914 [============================>.] - ETA: 0s - loss: 0.5874 - accuracy: 0.7362\n",
      "Epoch 2: val_loss improved from 0.68605 to 0.68332, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "914/914 [==============================] - 42s 46ms/step - loss: 0.5875 - accuracy: 0.7362 - val_loss: 0.6833 - val_accuracy: 0.7819 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.5448 - accuracy: 0.7499\n",
      "Epoch 3: val_loss did not improve from 0.68332\n",
      "914/914 [==============================] - 42s 46ms/step - loss: 0.5448 - accuracy: 0.7499 - val_loss: 0.7490 - val_accuracy: 0.3873 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "914/914 [==============================] - ETA: 0s - loss: 0.5300 - accuracy: 0.7598\n",
      "Epoch 4: val_loss improved from 0.68332 to 0.63249, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "914/914 [==============================] - 42s 46ms/step - loss: 0.5300 - accuracy: 0.7598 - val_loss: 0.6325 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "914/914 [==============================] - ETA: 0s - loss: 0.5098 - accuracy: 0.7791\n",
      "Epoch 5: val_loss did not improve from 0.63249\n",
      "914/914 [==============================] - 43s 47ms/step - loss: 0.5098 - accuracy: 0.7791 - val_loss: 0.6557 - val_accuracy: 0.7232 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.5009 - accuracy: 0.7887\n",
      "Epoch 6: val_loss improved from 0.63249 to 0.62340, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "914/914 [==============================] - 43s 47ms/step - loss: 0.5009 - accuracy: 0.7887 - val_loss: 0.6234 - val_accuracy: 0.7626 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.4870 - accuracy: 0.7975\n",
      "Epoch 7: val_loss improved from 0.62340 to 0.61714, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "914/914 [==============================] - 42s 46ms/step - loss: 0.4869 - accuracy: 0.7975 - val_loss: 0.6171 - val_accuracy: 0.7536 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "914/914 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.8053\n",
      "Epoch 8: val_loss improved from 0.61714 to 0.58511, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "914/914 [==============================] - 42s 46ms/step - loss: 0.4811 - accuracy: 0.8053 - val_loss: 0.5851 - val_accuracy: 0.7754 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "914/914 [==============================] - ETA: 0s - loss: 0.4762 - accuracy: 0.8044\n",
      "Epoch 9: val_loss did not improve from 0.58511\n",
      "914/914 [==============================] - 42s 46ms/step - loss: 0.4762 - accuracy: 0.8044 - val_loss: 0.5958 - val_accuracy: 0.7680 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "914/914 [==============================] - ETA: 0s - loss: 0.4739 - accuracy: 0.8115\n",
      "Epoch 10: val_loss did not improve from 0.58511\n",
      "914/914 [==============================] - 42s 46ms/step - loss: 0.4739 - accuracy: 0.8115 - val_loss: 0.6381 - val_accuracy: 0.7244 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "914/914 [==============================] - ETA: 0s - loss: 0.4604 - accuracy: 0.8166\n",
      "Epoch 11: val_loss improved from 0.58511 to 0.55196, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "914/914 [==============================] - 42s 46ms/step - loss: 0.4604 - accuracy: 0.8166 - val_loss: 0.5520 - val_accuracy: 0.7951 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.4587 - accuracy: 0.8191\n",
      "Epoch 12: val_loss did not improve from 0.55196\n",
      "914/914 [==============================] - 42s 46ms/step - loss: 0.4586 - accuracy: 0.8191 - val_loss: 0.5644 - val_accuracy: 0.7959 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "914/914 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.8201\n",
      "Epoch 13: val_loss improved from 0.55196 to 0.54527, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "914/914 [==============================] - 42s 46ms/step - loss: 0.4567 - accuracy: 0.8201 - val_loss: 0.5453 - val_accuracy: 0.8070 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.4481 - accuracy: 0.8276\n",
      "Epoch 14: val_loss improved from 0.54527 to 0.52691, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "914/914 [==============================] - 42s 46ms/step - loss: 0.4481 - accuracy: 0.8276 - val_loss: 0.5269 - val_accuracy: 0.8025 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "914/914 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.8254\n",
      "Epoch 15: val_loss improved from 0.52691 to 0.51414, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "914/914 [==============================] - 42s 46ms/step - loss: 0.4511 - accuracy: 0.8254 - val_loss: 0.5141 - val_accuracy: 0.8099 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.4421 - accuracy: 0.8311\n",
      "Epoch 16: val_loss did not improve from 0.51414\n",
      "914/914 [==============================] - 42s 46ms/step - loss: 0.4422 - accuracy: 0.8311 - val_loss: 0.5285 - val_accuracy: 0.8041 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.4430 - accuracy: 0.8300\n",
      "Epoch 17: val_loss improved from 0.51414 to 0.51400, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "914/914 [==============================] - 42s 46ms/step - loss: 0.4430 - accuracy: 0.8300 - val_loss: 0.5140 - val_accuracy: 0.8062 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.4406 - accuracy: 0.8303\n",
      "Epoch 18: val_loss improved from 0.51400 to 0.49216, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "914/914 [==============================] - 42s 46ms/step - loss: 0.4406 - accuracy: 0.8303 - val_loss: 0.4922 - val_accuracy: 0.8127 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "914/914 [==============================] - ETA: 0s - loss: 0.4351 - accuracy: 0.8290\n",
      "Epoch 19: val_loss did not improve from 0.49216\n",
      "914/914 [==============================] - 43s 47ms/step - loss: 0.4351 - accuracy: 0.8290 - val_loss: 0.5137 - val_accuracy: 0.8057 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.4346 - accuracy: 0.8317\n",
      "Epoch 20: val_loss improved from 0.49216 to 0.48876, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "914/914 [==============================] - 43s 47ms/step - loss: 0.4345 - accuracy: 0.8317 - val_loss: 0.4888 - val_accuracy: 0.8168 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.4309 - accuracy: 0.8326\n",
      "Epoch 21: val_loss did not improve from 0.48876\n",
      "914/914 [==============================] - 43s 47ms/step - loss: 0.4310 - accuracy: 0.8326 - val_loss: 0.5190 - val_accuracy: 0.8070 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "914/914 [==============================] - ETA: 0s - loss: 0.4336 - accuracy: 0.8343\n",
      "Epoch 22: val_loss did not improve from 0.48876\n",
      "914/914 [==============================] - 42s 46ms/step - loss: 0.4336 - accuracy: 0.8343 - val_loss: 0.5205 - val_accuracy: 0.8057 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.4287 - accuracy: 0.8352\n",
      "Epoch 23: val_loss did not improve from 0.48876\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "914/914 [==============================] - 35s 38ms/step - loss: 0.4287 - accuracy: 0.8352 - val_loss: 0.5129 - val_accuracy: 0.8107 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.4092 - accuracy: 0.8462\n",
      "Epoch 24: val_loss did not improve from 0.48876\n",
      "914/914 [==============================] - 34s 37ms/step - loss: 0.4092 - accuracy: 0.8461 - val_loss: 0.5056 - val_accuracy: 0.8107 - lr: 5.0000e-04\n",
      "Epoch 25/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.4056 - accuracy: 0.8502\n",
      "Epoch 25: val_loss did not improve from 0.48876\n",
      "914/914 [==============================] - 34s 37ms/step - loss: 0.4056 - accuracy: 0.8502 - val_loss: 0.4995 - val_accuracy: 0.8099 - lr: 5.0000e-04\n",
      "Epoch 26/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.4039 - accuracy: 0.8456\n",
      "Epoch 26: val_loss improved from 0.48876 to 0.47566, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "914/914 [==============================] - 34s 38ms/step - loss: 0.4039 - accuracy: 0.8457 - val_loss: 0.4757 - val_accuracy: 0.8144 - lr: 5.0000e-04\n",
      "Epoch 27/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.4058 - accuracy: 0.8483\n",
      "Epoch 27: val_loss did not improve from 0.47566\n",
      "914/914 [==============================] - 34s 37ms/step - loss: 0.4058 - accuracy: 0.8483 - val_loss: 0.4828 - val_accuracy: 0.8156 - lr: 5.0000e-04\n",
      "Epoch 28/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.4008 - accuracy: 0.8490\n",
      "Epoch 28: val_loss did not improve from 0.47566\n",
      "914/914 [==============================] - 35s 38ms/step - loss: 0.4007 - accuracy: 0.8490 - val_loss: 0.5380 - val_accuracy: 0.8021 - lr: 5.0000e-04\n",
      "Epoch 29/30\n",
      "913/914 [============================>.] - ETA: 0s - loss: 0.4037 - accuracy: 0.8478\n",
      "Epoch 29: val_loss did not improve from 0.47566\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "914/914 [==============================] - 37s 41ms/step - loss: 0.4038 - accuracy: 0.8477 - val_loss: 0.5330 - val_accuracy: 0.8070 - lr: 5.0000e-04\n",
      "Epoch 30/30\n",
      "912/914 [============================>.] - ETA: 0s - loss: 0.3905 - accuracy: 0.8557\n",
      "Epoch 30: val_loss improved from 0.47566 to 0.47322, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "914/914 [==============================] - 38s 42ms/step - loss: 0.3904 - accuracy: 0.8558 - val_loss: 0.4732 - val_accuracy: 0.8177 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "# Define the model checkpoint\n",
    "checkpoint_path = \"best_model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=[0, 1], y=y_train)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_ctrain, y_ctrain, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    epochs=30, \n",
    "                    batch_size=16,\n",
    "                    class_weight=class_weights_dict,\n",
    "                    callbacks=[checkpoint, reduce_lr, early_stopping]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7dcdd2c-e97e-4fdf-88ef-f41b6678ff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 65.00%\n",
      "540/540 [==============================] - 9s 17ms/step\n",
      "Total Accuracy (TAC): 65.00%\n",
      "Sensitivity (SE): 75.60%\n",
      "Specificity (SP): 58.52%\n",
      "Positive Predictive Value (PPV): 52.69%\n",
      "Negative Predictive Value (NPV): 79.70%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# Compute confusion matrix and evaluation metrics\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "TAC = (tp + tn) / (tp + tn + fp + fn) * 100\n",
    "sensitivity = tp / (tp + fn) * 100\n",
    "specificity = tn / (tn + fp) * 100\n",
    "PPV = tp / (tp + fp) * 100\n",
    "NPV = tn / (tn + fn) * 100\n",
    "kappa = cohen_kappa_score(y_test, y_test_pred)\n",
    "\n",
    "# Display metrics\n",
    "print(f\"Total Accuracy (TAC): {TAC:.2f}%\")\n",
    "print(f\"Sensitivity (SE): {sensitivity:.2f}%\")\n",
    "print(f\"Specificity (SP): {specificity:.2f}%\")\n",
    "print(f\"Positive Predictive Value (PPV): {PPV:.2f}%\")\n",
    "print(f\"Negative Predictive Value (NPV): {NPV:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967bb32e-7907-47df-ba7d-2527c4584862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
