{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "566d29cd-c051-445b-a965-9bdd81b2e32f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\abbas\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import os\n",
    "import scipy.signal as sgn\n",
    "from tqdm import tqdm\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from scipy.signal import cheby1, filtfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837e9718-0d1f-4aea-bec8-49663ea1933e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# File paths\n",
    "train_files = [f\"a{str(i).zfill(2)}\" for i in range(1, 21)] + [f\"b{str(i).zfill(2)}\" for i in range(1, 6)] + [f\"c{str(i).zfill(2)}\" for i in range(1, 11)]\n",
    "test_files = [f\"x{str(i).zfill(2)}\" for i in range(1, 36)]\n",
    "base_path = \"apnea-ecg/1.0.0/\"\n",
    "train_paths = [os.path.join(base_path, file) for file in train_files]\n",
    "test_paths = [os.path.join(base_path, file) for file in test_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dede400d-6537-4615-a578-474ebcefc295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Chebyshev Filter\n",
    "def apply_chebyshev_filter(signal, lowcut=0.5, highcut=40, fs=100, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = cheby1(order, 0.5, [low, high], btype='band')\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "# Function to load and preprocess the ECG signal\n",
    "def load_ecg_and_segment(file, segment_duration=60, fs=100):\n",
    "    if not os.path.exists(f\"{file}.hea\") or not os.path.exists(f\"{file}.dat\"):\n",
    "        print(f\"File not found: {file}.hea or {file}.dat\")\n",
    "        return [], []\n",
    "    \n",
    "    record = wfdb.rdrecord(file)\n",
    "    annotation = wfdb.rdann(file, 'apn')\n",
    "\n",
    "    signal = record.p_signal[:, 0]\n",
    "    filtered_signal = apply_chebyshev_filter(signal)\n",
    "\n",
    "    segments = []\n",
    "    labels = []\n",
    "    samples_per_segment = segment_duration * fs\n",
    "\n",
    "    for i, samp in enumerate(annotation.sample):\n",
    "        start = max(samp - samples_per_segment // 2, 0)\n",
    "        end = start + samples_per_segment\n",
    "        if end > len(filtered_signal):\n",
    "            break\n",
    "        segment = filtered_signal[start:end]\n",
    "        segments.append(segment)\n",
    "        labels.append(1 if annotation.symbol[i] == 'A' else 0)\n",
    "        \n",
    "    return np.array(segments), np.array(labels)\n",
    "\n",
    "# Load and prepare the full dataset\n",
    "def prepare_data(paths):\n",
    "    data, labels = [], []\n",
    "    for path in tqdm(paths):\n",
    "        segments, seg_labels = load_ecg_and_segment(path)\n",
    "        if segments.size > 0:  \n",
    "            data.extend(segments)\n",
    "            labels.extend(seg_labels)\n",
    "    return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55da9faf-3c12-4234-842c-e747d976c979",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:04<00:00,  7.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:04<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training segments: 17030, Test segments: 17260\n",
      "Training data shape: (17030, 6000, 1)\n",
      "Training labels shape: (17030,)\n",
      "Test data shape: (17260, 6000, 1)\n",
      "Test labels shape: (17260,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load training and validation data, and shuffle\n",
    "X_train, y_train = prepare_data(train_paths)\n",
    "X_test, y_test = prepare_data(test_paths)\n",
    "\n",
    "# Shuffle the data\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "# Print the number of segments loaded for verification\n",
    "print(f\"Training segments: {len(X_train)}, Test segments: {len(X_test)}\")\n",
    "\n",
    "# Reshape data for model input format\n",
    "X_train = X_train[..., np.newaxis]  # Adding channel dimension\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a994c426-59e4-4a7b-bf20-dbb35dcece8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (14597, 6000, 1)\n",
      "Validation data shape: (2433, 6000, 1)\n",
      "Train labels shape: (14597,)\n",
      "Validation labels shape: (2433,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Splitting the training data into train and validation sets with StratifiedKFold\n",
    "strat_kfold = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "train_indices, val_indices = next(strat_kfold.split(X_train, y_train))\n",
    "\n",
    "# Creating training and validation sets\n",
    "X_ctrain, X_val = X_train[train_indices], X_train[val_indices]\n",
    "y_ctrain, y_val = y_train[train_indices], y_train[val_indices]\n",
    "\n",
    "# Print shapes of the resulting sets for verification\n",
    "print(\"Train data shape:\", X_ctrain.shape)\n",
    "print(\"Validation data shape:\", X_val.shape)\n",
    "print(\"Train labels shape:\", y_ctrain.shape)\n",
    "print(\"Validation labels shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c624576-e26e-4a11-a86b-ae445d0e4e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, regularizers, optimizers\n",
    "\n",
    "def build_cnn_lstm_model(input_shape):\n",
    "    # Input layer\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x_bn = layers.BatchNormalization()(input_layer)\n",
    "    \n",
    "    # First branch: Conv1D with kernel size 125 and MaxPooling with L2 regularization\n",
    "    branch1 = layers.Conv1D(24, kernel_size=125, strides=1, activation='relu', \n",
    "                            padding='same', kernel_regularizer=regularizers.l2(0.001))(x_bn)\n",
    "    branch1 = layers.MaxPooling1D(pool_size=2, strides=1, padding='same')(branch1)\n",
    "    \n",
    "    # Second branch: Conv1D with kernel size 15 and MaxPooling with L2 regularization\n",
    "    branch2 = layers.Conv1D(24, kernel_size=15, strides=1, activation='relu', \n",
    "                            padding='same', kernel_regularizer=regularizers.l2(0.001))(x_bn)\n",
    "    branch2 = layers.MaxPooling1D(pool_size=2, strides=1, padding='same')(branch2)\n",
    "    \n",
    "    # Third branch: Conv1D with kernel size 5 and MaxPooling with L2 regularization\n",
    "    branch3 = layers.Conv1D(24, kernel_size=5, strides=1, activation='relu', \n",
    "                            padding='same', kernel_regularizer=regularizers.l2(0.001))(x_bn)\n",
    "    branch3 = layers.MaxPooling1D(pool_size=2, strides=1, padding='same')(branch3)\n",
    "    \n",
    "    # Concatenate the outputs of the three branches\n",
    "    concatenated = layers.Concatenate(axis=-1)([branch1, branch2, branch3])\n",
    "    \n",
    "    # Additional MaxPooling after concatenation\n",
    "    x = layers.MaxPooling1D(pool_size=3, strides=1, padding='same')(concatenated)\n",
    "    \n",
    "    # Adjust the Conv1D layer to match dimensions for addition\n",
    "    conv_adjusted = layers.Conv1D(72, kernel_size=3, strides=1, activation='relu', \n",
    "                                  padding='same', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.Add()([x, conv_adjusted])\n",
    "    \n",
    "    # Fully Connected and Dropout layers with L2 regularization\n",
    "    x = layers.Dense(48, activation='leaky_relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.Dropout(0.5)(x)  # Dropout for regularization\n",
    "    \n",
    "    # Global Pooling layer\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # LSTM layer\n",
    "    # x = layers.Reshape((1, -1))(x)  # Reshape for LSTM input\n",
    "    # x = layers.LSTM(64, kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    \n",
    "    # Output layer\n",
    "    output_layer = layers.Dense(2, activation='softmax', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    \n",
    "    # Define the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da14a4f4-9571-4ec0-af55-5f6437a78fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 6000, 1)]            0         []                            \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 6000, 1)              4         ['input_2[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 6000, 24)             3024      ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 6000, 24)             384       ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)           (None, 6000, 24)             144       ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPoolin  (None, 6000, 24)             0         ['conv1d_4[0][0]']            \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPoolin  (None, 6000, 24)             0         ['conv1d_5[0][0]']            \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPoolin  (None, 6000, 24)             0         ['conv1d_6[0][0]']            \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 6000, 72)             0         ['max_pooling1d_4[0][0]',     \n",
      " )                                                                   'max_pooling1d_5[0][0]',     \n",
      "                                                                     'max_pooling1d_6[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPoolin  (None, 6000, 72)             0         ['concatenate_1[0][0]']       \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)           (None, 6000, 72)             15624     ['max_pooling1d_7[0][0]']     \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 6000, 72)             0         ['max_pooling1d_7[0][0]',     \n",
      "                                                                     'conv1d_7[0][0]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 6000, 48)             3504      ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 6000, 48)             0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 48)                   0         ['dropout_1[0][0]']           \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 2)                    98        ['global_average_pooling1d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22782 (88.99 KB)\n",
      "Trainable params: 22780 (88.98 KB)\n",
      "Non-trainable params: 2 (8.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compile the model with specified learning rate\n",
    "input_shape = (6000, 1)  # Adjust as per 10-second segments at 100 Hz sampling rate\n",
    "model = build_cnn_lstm_model(input_shape)\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model summary for verification\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17fb9435-c9ec-4c0a-9cc2-4c7b4392a9b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Users\\abbas\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\abbas\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.6791 - accuracy: 0.6873\n",
      "Epoch 1: val_loss improved from inf to 0.67638, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "913/913 [==============================] - 285s 310ms/step - loss: 0.6791 - accuracy: 0.6873 - val_loss: 0.6764 - val_accuracy: 0.6441 - lr: 0.0010\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913/913 [==============================] - ETA: 0s - loss: 0.5781 - accuracy: 0.7484\n",
      "Epoch 2: val_loss improved from 0.67638 to 0.66586, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "913/913 [==============================] - 278s 304ms/step - loss: 0.5781 - accuracy: 0.7484 - val_loss: 0.6659 - val_accuracy: 0.7789 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.7804\n",
      "Epoch 3: val_loss improved from 0.66586 to 0.61520, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "913/913 [==============================] - 279s 305ms/step - loss: 0.5253 - accuracy: 0.7804 - val_loss: 0.6152 - val_accuracy: 0.6712 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.5025 - accuracy: 0.7927\n",
      "Epoch 4: val_loss improved from 0.61520 to 0.60159, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "913/913 [==============================] - 278s 305ms/step - loss: 0.5025 - accuracy: 0.7927 - val_loss: 0.6016 - val_accuracy: 0.7855 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.8055\n",
      "Epoch 5: val_loss improved from 0.60159 to 0.59471, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "913/913 [==============================] - 280s 307ms/step - loss: 0.4849 - accuracy: 0.8055 - val_loss: 0.5947 - val_accuracy: 0.7855 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.8160\n",
      "Epoch 6: val_loss did not improve from 0.59471\n",
      "913/913 [==============================] - 294s 322ms/step - loss: 0.4716 - accuracy: 0.8160 - val_loss: 0.6025 - val_accuracy: 0.7867 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.4583 - accuracy: 0.8226\n",
      "Epoch 7: val_loss improved from 0.59471 to 0.59443, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "913/913 [==============================] - 278s 304ms/step - loss: 0.4583 - accuracy: 0.8226 - val_loss: 0.5944 - val_accuracy: 0.7797 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.4500 - accuracy: 0.8293\n",
      "Epoch 8: val_loss improved from 0.59443 to 0.54850, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "913/913 [==============================] - 280s 307ms/step - loss: 0.4500 - accuracy: 0.8293 - val_loss: 0.5485 - val_accuracy: 0.8113 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.4417 - accuracy: 0.8379\n",
      "Epoch 9: val_loss improved from 0.54850 to 0.54755, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "913/913 [==============================] - 279s 306ms/step - loss: 0.4417 - accuracy: 0.8379 - val_loss: 0.5475 - val_accuracy: 0.8015 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.4312 - accuracy: 0.8409\n",
      "Epoch 10: val_loss improved from 0.54755 to 0.52732, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "913/913 [==============================] - 276s 303ms/step - loss: 0.4312 - accuracy: 0.8409 - val_loss: 0.5273 - val_accuracy: 0.8229 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.4212 - accuracy: 0.8481\n",
      "Epoch 11: val_loss improved from 0.52732 to 0.50209, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "913/913 [==============================] - 280s 307ms/step - loss: 0.4212 - accuracy: 0.8481 - val_loss: 0.5021 - val_accuracy: 0.8245 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.4227 - accuracy: 0.8443\n",
      "Epoch 12: val_loss did not improve from 0.50209\n",
      "913/913 [==============================] - 271s 297ms/step - loss: 0.4227 - accuracy: 0.8443 - val_loss: 0.5080 - val_accuracy: 0.8282 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.4201 - accuracy: 0.8473\n",
      "Epoch 13: val_loss did not improve from 0.50209\n",
      "913/913 [==============================] - 258s 282ms/step - loss: 0.4201 - accuracy: 0.8473 - val_loss: 0.5315 - val_accuracy: 0.8031 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.4108 - accuracy: 0.8526\n",
      "Epoch 14: val_loss improved from 0.50209 to 0.47176, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "913/913 [==============================] - 266s 292ms/step - loss: 0.4108 - accuracy: 0.8526 - val_loss: 0.4718 - val_accuracy: 0.8303 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.4116 - accuracy: 0.8504\n",
      "Epoch 15: val_loss did not improve from 0.47176\n",
      "913/913 [==============================] - 264s 290ms/step - loss: 0.4116 - accuracy: 0.8504 - val_loss: 0.4891 - val_accuracy: 0.8303 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.4080 - accuracy: 0.8564\n",
      "Epoch 16: val_loss did not improve from 0.47176\n",
      "913/913 [==============================] - 264s 289ms/step - loss: 0.4080 - accuracy: 0.8564 - val_loss: 0.4808 - val_accuracy: 0.8270 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.4068 - accuracy: 0.8533\n",
      "Epoch 17: val_loss did not improve from 0.47176\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "913/913 [==============================] - 265s 291ms/step - loss: 0.4068 - accuracy: 0.8533 - val_loss: 0.5430 - val_accuracy: 0.7928 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.3889 - accuracy: 0.8641\n",
      "Epoch 18: val_loss improved from 0.47176 to 0.45415, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "913/913 [==============================] - 265s 291ms/step - loss: 0.3889 - accuracy: 0.8641 - val_loss: 0.4542 - val_accuracy: 0.8298 - lr: 5.0000e-04\n",
      "Epoch 19/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.3823 - accuracy: 0.8676\n",
      "Epoch 19: val_loss improved from 0.45415 to 0.44026, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "913/913 [==============================] - 267s 292ms/step - loss: 0.3823 - accuracy: 0.8676 - val_loss: 0.4403 - val_accuracy: 0.8368 - lr: 5.0000e-04\n",
      "Epoch 20/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.8702\n",
      "Epoch 20: val_loss did not improve from 0.44026\n",
      "913/913 [==============================] - 269s 295ms/step - loss: 0.3738 - accuracy: 0.8702 - val_loss: 0.4843 - val_accuracy: 0.8290 - lr: 5.0000e-04\n",
      "Epoch 21/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.3794 - accuracy: 0.8657\n",
      "Epoch 21: val_loss improved from 0.44026 to 0.43961, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "913/913 [==============================] - 264s 289ms/step - loss: 0.3794 - accuracy: 0.8657 - val_loss: 0.4396 - val_accuracy: 0.8418 - lr: 5.0000e-04\n",
      "Epoch 22/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.3749 - accuracy: 0.8698\n",
      "Epoch 22: val_loss did not improve from 0.43961\n",
      "913/913 [==============================] - 258s 283ms/step - loss: 0.3749 - accuracy: 0.8698 - val_loss: 0.4424 - val_accuracy: 0.8459 - lr: 5.0000e-04\n",
      "Epoch 23/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.3766 - accuracy: 0.8680\n",
      "Epoch 23: val_loss did not improve from 0.43961\n",
      "913/913 [==============================] - 252s 277ms/step - loss: 0.3766 - accuracy: 0.8680 - val_loss: 0.4473 - val_accuracy: 0.8463 - lr: 5.0000e-04\n",
      "Epoch 24/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.3709 - accuracy: 0.8702\n",
      "Epoch 24: val_loss improved from 0.43961 to 0.42616, saving model to C:/Users/abbas/BAU/11Fall 2024/FYP2/apnea-ecg/1.0.0/Model_CheckPoint_draft_3\\best_model.h5\n",
      "913/913 [==============================] - 255s 279ms/step - loss: 0.3709 - accuracy: 0.8702 - val_loss: 0.4262 - val_accuracy: 0.8438 - lr: 5.0000e-04\n",
      "Epoch 25/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.3669 - accuracy: 0.8752\n",
      "Epoch 25: val_loss did not improve from 0.42616\n",
      "913/913 [==============================] - 255s 279ms/step - loss: 0.3669 - accuracy: 0.8752 - val_loss: 0.4677 - val_accuracy: 0.8352 - lr: 5.0000e-04\n",
      "Epoch 26/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.8728\n",
      "Epoch 26: val_loss did not improve from 0.42616\n",
      "913/913 [==============================] - 251s 275ms/step - loss: 0.3658 - accuracy: 0.8728 - val_loss: 0.4504 - val_accuracy: 0.8430 - lr: 5.0000e-04\n",
      "Epoch 27/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.8730\n",
      "Epoch 27: val_loss did not improve from 0.42616\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "913/913 [==============================] - 249s 273ms/step - loss: 0.3658 - accuracy: 0.8730 - val_loss: 0.4467 - val_accuracy: 0.8385 - lr: 5.0000e-04\n",
      "Epoch 28/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.3512 - accuracy: 0.8796\n",
      "Epoch 28: val_loss did not improve from 0.42616\n",
      "913/913 [==============================] - 254s 278ms/step - loss: 0.3512 - accuracy: 0.8796 - val_loss: 0.4593 - val_accuracy: 0.8368 - lr: 2.5000e-04\n",
      "Epoch 29/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 0.8781\n",
      "Epoch 29: val_loss did not improve from 0.42616\n",
      "913/913 [==============================] - 250s 273ms/step - loss: 0.3547 - accuracy: 0.8781 - val_loss: 0.4499 - val_accuracy: 0.8413 - lr: 2.5000e-04\n",
      "Epoch 30/30\n",
      "913/913 [==============================] - ETA: 0s - loss: 0.3527 - accuracy: 0.8806\n",
      "Epoch 30: val_loss did not improve from 0.42616\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "913/913 [==============================] - 249s 273ms/step - loss: 0.3527 - accuracy: 0.8806 - val_loss: 0.4300 - val_accuracy: 0.8487 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "# Define the model checkpoint\n",
    "checkpoint_path = \"=best_model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=[0, 1], y=y_train)\n",
    "class_weights_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_ctrain, y_ctrain, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    epochs=30, \n",
    "                    batch_size=16,\n",
    "                    class_weight=class_weights_dict,\n",
    "                    callbacks=[checkpoint, reduce_lr, early_stopping]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7dcdd2c-e97e-4fdf-88ef-f41b6678ff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 65.72%\n",
      "540/540 [==============================] - 63s 116ms/step\n",
      "Total Accuracy (TAC): 65.72%\n",
      "Sensitivity (SE): 77.32%\n",
      "Specificity (SP): 58.63%\n",
      "Positive Predictive Value (PPV): 53.32%\n",
      "Negative Predictive Value (NPV): 80.88%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# Compute confusion matrix and evaluation metrics\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "TAC = (tp + tn) / (tp + tn + fp + fn) * 100\n",
    "sensitivity = tp / (tp + fn) * 100\n",
    "specificity = tn / (tn + fp) * 100\n",
    "PPV = tp / (tp + fp) * 100\n",
    "NPV = tn / (tn + fn) * 100\n",
    "kappa = cohen_kappa_score(y_test, y_test_pred)\n",
    "\n",
    "# Display metrics\n",
    "print(f\"Total Accuracy (TAC): {TAC:.2f}%\")\n",
    "print(f\"Sensitivity (SE): {sensitivity:.2f}%\")\n",
    "print(f\"Specificity (SP): {specificity:.2f}%\")\n",
    "print(f\"Positive Predictive Value (PPV): {PPV:.2f}%\")\n",
    "print(f\"Negative Predictive Value (NPV): {NPV:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967bb32e-7907-47df-ba7d-2527c4584862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
